{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c31dd1-81dc-4a82-a7c0-f6e10b2bda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import torch \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6552191c-3c91-49ae-8d29-bddf1fa84395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "80366a3e-5238-45a4-880b-42345d10db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toeplitz_1_ch(kernel, input_size):\n",
    "    # shapes\n",
    "    k_h, k_w = kernel.shape\n",
    "    i_h, i_w = input_size\n",
    "    o_h, o_w = i_h-k_h+1, i_w-k_w+1\n",
    "\n",
    "    # construct 1d conv toeplitz matrices for each row of the kernel\n",
    "    toeplitz = []\n",
    "    for r in range(k_h):\n",
    "        toeplitz.append(linalg.toeplitz(c=(kernel[r,0], *np.zeros(i_w-k_w)), r=(*kernel[r], *np.zeros(i_w-k_w))) ) \n",
    "\n",
    "    # construct toeplitz matrix of toeplitz matrices (just for padding=0)\n",
    "    h_blocks, w_blocks = o_h, i_h\n",
    "    h_block, w_block = toeplitz[0].shape\n",
    "\n",
    "    W_conv = np.zeros((h_blocks, h_block, w_blocks, w_block))\n",
    "\n",
    "    for i, B in enumerate(toeplitz):\n",
    "        for j in range(o_h):\n",
    "            W_conv[j, :, i+j, :] = B\n",
    "\n",
    "    W_conv.shape = (h_blocks*h_block, w_blocks*w_block)\n",
    "\n",
    "    return W_conv\n",
    "\n",
    "def toeplitz_mult_ch(kernel, input_size):\n",
    "    \"\"\"Compute toeplitz matrix for 2d conv with multiple in and out channels.\n",
    "    Args:\n",
    "        kernel: shape=(n_out, n_in, H_k, W_k)\n",
    "        input_size: (n_in, H_i, W_i)\"\"\"\n",
    "\n",
    "    kernel_size = kernel.shape\n",
    "    output_size = (kernel_size[0], input_size[1] - (kernel_size[2] - 1), input_size[2] - (kernel_size[3] - 1))\n",
    "    print (output_size)\n",
    "    T = np.zeros((output_size[0], int(np.prod(output_size[1:])), input_size[0], int(np.prod(input_size[1:]))))\n",
    "\n",
    "    for i, ks in enumerate(kernel):  # loop over output channel\n",
    "        for j, k in enumerate(ks):  # loop over input channel\n",
    "            T_k = toeplitz_1_ch(k, input_size[1:])\n",
    "            T[i, :, j, :] = T_k\n",
    "\n",
    "    T.shape = (np.prod(output_size), np.prod(input_size))\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdb52689-92d4-450e-8e51-ba0647a3404d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.271357924035143e-28\n"
     ]
    }
   ],
   "source": [
    "# k = np.random.randn(8, 3, 3, 3)\n",
    "# i = np.random.randn(3, 10, 12)\n",
    "\n",
    "# T = toeplitz_mult_ch(k, i.shape)\n",
    "# out = T.dot(i.flatten()).reshape((1, 8, 8, 10))\n",
    "\n",
    "# check correctness of convolution via toeplitz matrix\n",
    "print(np.sum((out - F.conv2d(torch.tensor(i).view(1,3,10,12), torch.tensor(k)).numpy())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9e6a6cbe-2c3f-4313-9a9f-745b8b8052c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 48, 841]) torch.Size([48, 2])\n",
      "torch.Size([32, 2, 841])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5.1425e-08)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n",
    "inp = torch.randn(32, 3, 32, 32)\n",
    "w = torch.randn(2, 3, 4, 4)\n",
    "inp_unf = torch.nn.functional.unfold(inp, (4, 4), stride=1, padding=0)\n",
    "print (inp_unf.shape, w.view(w.size(0), -1).t().shape)\n",
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "print (out_unf.shape)\n",
    "out = out_unf.view(32, 2, 29, 29)\n",
    "torch.sum((F.conv2d(inp, w, stride=1, padding=0) - out)**2)\n",
    "# tensor(1.9073e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "82b55289-0201-4bea-b58e-81227adb7a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 29, 29)\n",
      "(1682,)\n"
     ]
    }
   ],
   "source": [
    "T = toeplitz_mult_ch(w, inp.squeeze().shape)\n",
    "out_toe = T.dot(inp.flatten())\n",
    "print (out_toe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "deccd2f6-b265-46c2-b7c6-2575d116cfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 48]) torch.Size([32, 2, 841]) torch.Size([32, 48, 841])\n"
     ]
    }
   ],
   "source": [
    "z = out_unf \n",
    "fc = torch.sum(z**2, axis=0)\n",
    "fc = torch.mean(fc)\n",
    "aW_unf = torch.zeros(w.view(w.size(0), -1).shape)\n",
    "\n",
    "if fc > 0:\n",
    "    tW = aW_unf\n",
    "    for k in range(1):\n",
    "        tW += 2 * (z[k, :] @ inp_unf[k, :].T)\n",
    "    aW_unf = -fc * tW / torch.linalg.norm(tW)**2\n",
    "    \n",
    "print (aW_unf.shape, out_unf.shape, inp_unf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "45cd9629-5676-4b6f-8f89-269b5bd53e93",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [1682] and src [3072] to have the same number of elements, but got 1682 and 3072 elements respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [152], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m tW \u001b[38;5;241m=\u001b[39m aW_toe\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     tW \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m)\n\u001b[1;32m     10\u001b[0m aW_toe \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mfc \u001b[38;5;241m*\u001b[39m tW \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(tW)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [1682] and src [3072] to have the same number of elements, but got 1682 and 3072 elements respectively"
     ]
    }
   ],
   "source": [
    "z = torch.from_numpy(out_toe).view(1, -1).float()\n",
    "fc = torch.sum(z**2, axis=0)\n",
    "fc = torch.mean(fc)\n",
    "aW_toe = torch.zeros(T.shape)\n",
    "\n",
    "if fc > 0:\n",
    "    tW = aW_toe\n",
    "    for k in range(1):\n",
    "        tW += 2 * (z[k, :] @ inp[k, :].flatten().T)\n",
    "    aW_toe = -fc * tW / torch.linalg.norm(tW)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c2ad0d88-193e-42c2-b187-bc7072c7bbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 29, 29), torch.Size([1, 3, 32, 32]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_toe.reshape(1, 2, 29, 29).shape, inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7558643-48c6-4b58-ba5c-e9ef8728f3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
