{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c9e0b6c-7a6b-42c2-a583-9ed416807cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "from liptrf.models.vit import L2Attention, ViT\n",
    "from liptrf.models.layers import trunc, l2_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f18b8101-18f6-4fce-81b7-dbe7a3adc4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e8838b8-ad68-48f1-baae-18e70f831e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5563016"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9679a5f-0a70-459a-97b9-207e0fc05559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 3, 16, 16])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.patch_embed.proj.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b545c2f4-d969-4c33-ba9d-72316d5f01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedX(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, norm_layer=None, flatten=True, iter=5, lmbda=2.5, relax=1, lr=1, eta=1e-7):\n",
    "        super(PatchEmbedX, self).__init__()\n",
    "        img_size = (img_size, img_size)\n",
    "        patch_size = (patch_size, patch_size)\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.grid_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1])\n",
    "        self.num_patches = self.grid_size[0] * self.grid_size[1]\n",
    "        self.flatten = flatten\n",
    "        self.iter = iter \n",
    "        self.lmbda = lmbda\n",
    "        self.relax = relax \n",
    "        self.lr = lr \n",
    "        self.eta = eta\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.Tensor(embed_dim, in_chans, patch_size[0], patch_size[0]))\n",
    "        self.bias = nn.Parameter(torch.Tensor(embed_dim))\n",
    "        self.rand_x = nn.Parameter(trunc([1, in_chans, patch_size[0], patch_size[0]]), requires_grad=False)\n",
    "\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\"\n",
    "        assert W == self.img_size[1], f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\"\n",
    "        x = F.conv2d(x, self.weight, self.bias, stride=self.patch_size)\n",
    "        if self.flatten:\n",
    "            x = x.flatten(2).transpose(1, 2)  # BCHW -> BNC\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "    def lipschitz(self):\n",
    "        for i in range(self.iter):\n",
    "            x = l2_normalize(self.rand_x)\n",
    "            x_p = F.conv2d(x, self.weight, stride=self.patch_size)\n",
    "            self.rand_x = nn.Parameter(F.conv_transpose2d(x_p, self.weight, stride=self.patch_size), requires_grad=False)\n",
    "        \n",
    "        Wx = F.conv2d(self.rand_x, self.weight, stride=self.patch_size)\n",
    "        self.lc = torch.sqrt(torch.sum(Wx**2) / (torch.sum(x**2) + 1e-9)).data.cpu()\n",
    "        del x, x_p, Wx\n",
    "        torch.cuda.empty_cache()\n",
    "        return self.lc\n",
    "\n",
    "    def apply_spec(self):\n",
    "        fc = self.weight.clone().detach()\n",
    "        # print (fc.max())\n",
    "        fc = fc * 1 / (max(1, self.lc / self.lmbda))\n",
    "        # print (fc.max(), self.lc, self.lmbda)\n",
    "        self.weight = nn.Parameter(fc)\n",
    "        del fc\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def prox(self):\n",
    "        self.lipschitz()\n",
    "        self.lmbda = self.relax\n",
    "        self.apply_spec()\n",
    "        self.prox_weight = self.weight.clone() #/ self.relax\n",
    "        self.proj_weight = 2 * self.prox_weight - self.weight.clone()\n",
    "        self.proj_weight_n = self.proj_weight.clone()\n",
    "\n",
    "    def proj(self):\n",
    "        # if torch.norm()\n",
    "        if torch.norm(self.proj_weight_n-self.proj_weight, 'fro') < self.eta * torch.norm(self.weight, 'fro'):\n",
    "            return \n",
    "\n",
    "        z = F.linear(self.inp, self.proj_weight_n) - self.out\n",
    "        if len(z.shape) == 3:\n",
    "            cjn = torch.mean(torch.sum(z**2, dim=[0, 1]) - self.eta)\n",
    "        else:\n",
    "            cjn = torch.mean(torch.sum(z**2, dim=0) - self.eta)\n",
    "\n",
    "        del_wn = torch.zeros(self.proj_weight_n.shape)\n",
    "        if cjn > 0:\n",
    "            if len(self.inp.shape) == 3:\n",
    "                num = 2 * torch.sum(torch.einsum(\"bnjd,bnci->bndc\", \n",
    "                                    z.unsqueeze(-2), \n",
    "                                    self.inp.unsqueeze(-1)), dim=[0, 1])\n",
    "            else:\n",
    "                num = 2 * torch.sum(torch.einsum(\"bjd,bci->bdc\", \n",
    "                                    z.unsqueeze(-2), \n",
    "                                    self.inp.unsqueeze(-1)), dim=0)\n",
    "            num = num / self.out.shape[-1]\n",
    "            den = torch.norm(num, 'fro')**2\n",
    "            del_wn = -cjn * num / den \n",
    "        \n",
    "        L = torch.sum(del_wn**2)\n",
    "        if L > 1e-22:\n",
    "            cW = self.proj_weight - self.proj_weight_n\n",
    "\n",
    "            pi_n =  -1 * (cW.T.flatten().unsqueeze(0) @ del_wn.flatten().unsqueeze(1))\n",
    "            mu_n = torch.norm(cW, p=2)**2\n",
    "            vu_n = torch.norm(del_wn, p=2)**2 \n",
    "            chi_n = mu_n * vu_n - pi_n**2 \n",
    "\n",
    "            if chi_n < 0:\n",
    "                chi_n = 0\n",
    "\n",
    "            # print (del_wn.max(), vu_n, chi_n, pi_n, mu_n)\n",
    "            if (chi_n == 0) and (pi_n >= 0):\n",
    "                self.proj_weight_n = self.proj_weight_n + del_wn\n",
    "            elif (chi_n > 0) and ((pi_n * vu_n) >= chi_n):\n",
    "                self.proj_weight_n = self.proj_weight + (1  + pi_n/vu_n) * del_wn\n",
    "            elif (chi_n > 0) and ((pi_n * vu_n) < chi_n):\n",
    "                self.proj_weight_n = self.proj_weight_n + vu_n / chi_n * (pi_n * cW - mu_n * del_wn)\n",
    "            else:\n",
    "                raise Exception(\"Error\")\n",
    "\n",
    "    def update(self):\n",
    "        self.proj_weight = self.proj_weight_n\n",
    "        self.weight += self.lr * (self.prox_weight - self.proj_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2fdd97ff-df09-4701-9a32-8a3192fbbade",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PatchEmbedX(iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b540f99c-daf8-4d35-90a1-c73a456b1fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(1, 3, 224, 224)\n",
    "pe(inp).shape\n",
    "pe.inp = inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba1e9765-04d2-41a8-8d3c-eb79c676bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe.prox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f9bc88b9-0f24-4544-a43c-8e03fa82f1e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a tensor with <= 2 dimensions, but self is 4D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36mPatchEmbedX.proj\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_weight_n\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_weight, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \n\u001b[0;32m---> 67\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj_weight_n\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(z\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     69\u001b[0m     cjn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39msum(z\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta)\n",
      "File \u001b[0;32m~/miniconda3/envs/liptrf/lib/python3.9/site-packages/torch/nn/functional.py:1753\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: t() expects a tensor with <= 2 dimensions, but self is 4D"
     ]
    }
   ],
   "source": [
    "pe.proj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc99f8ad-f435-43de-b336-75d88ce6cd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
